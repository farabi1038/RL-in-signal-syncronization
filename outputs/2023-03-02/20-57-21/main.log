[2023-03-02 20:57:22,038][__main__][INFO] - Training with the following config:
env:
  name: foothill_v1
  source: sumo_files/foothill.7am.sumocfg
  randomize: true
  seed: 1337
  render: false
  local_resolution: 300
  special_volume: None
  warmup: false
  warmup_steps: 100
  per_step: false
  custom_volume: None
train:
  train:
    status: true
    debug: false
    n_episodes: 300
    max_t: 50
    plan: plan_temp_7am_v2.csv
    split: phase_split_7am_v2.csv
test:
  test:
    status: false
    max_t: 4
    n_episodes: 2
    load: None
benchmark:
  benchmark:
    status: false
    max_t: 4
    n_episodes: 2
    split: phase_split_7am_v2.csv
    plan: plan_temp_7am_original.csv
model:
  model:
    name: ppo_v1
    cseed: 1337
    gpu: -1
    clip_threshold: 5
    bound_mean: true
    lr: 0.0003
    weight_decay: 0.0
    update_interval: 128
    batchsize: 32
    epochs: 10
    entropy_coef: 0.0
    standardize_advantages: false
state:
  state:
    name: v1
    normalize: false
action:
  action:
    name: v1
    seed: 1337
reward:
  reward:
    name: v1
    normalize: false
    slowness: false

[2023-03-02 20:57:22,055][__main__][INFO] - action space: Box(0.0, 1.0, (5,), float32)
[2023-03-02 20:57:22,055][__main__][INFO] - observation space: 4
[2023-03-02 20:57:28,260][env.env_v1][INFO] - inside env1 config:
env:
  name: foothill_v1
  source: sumo_files/foothill.7am.sumocfg
  randomize: true
  seed: 1337
  render: false
  local_resolution: 300
  special_volume: None
  warmup: false
  warmup_steps: 100
  per_step: false
  custom_volume: None
train:
  train:
    status: true
    debug: false
    n_episodes: 300
    max_t: 50
    plan: plan_temp_7am_v2.csv
    split: phase_split_7am_v2.csv
test:
  test:
    status: false
    max_t: 4
    n_episodes: 2
    load: None
benchmark:
  benchmark:
    status: false
    max_t: 4
    n_episodes: 2
    split: phase_split_7am_v2.csv
    plan: plan_temp_7am_original.csv
model:
  model:
    name: ppo_v1
    cseed: 1337
    gpu: -1
    clip_threshold: 5
    bound_mean: true
    lr: 0.0003
    weight_decay: 0.0
    update_interval: 128
    batchsize: 32
    epochs: 10
    entropy_coef: 0.0
    standardize_advantages: false
state:
  state:
    name: v1
    normalize: false
action:
  action:
    name: v1
    seed: 1337
reward:
  reward:
    name: v1
    normalize: false
    slowness: false

